{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.fsl import MultipleRegressDesign\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.pipeline.engine as pe  \n",
    "from nipype import Workflow, Node, MapNode, IdentityInterface, Function, DataSink, JoinNode, SelectFiles\n",
    "import os\n",
    "import os.path as op\n",
    "import argparse\n",
    "import glob\n",
    "from bids import BIDSLayout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = '/nese/mit/group/saxelab/projects/EMOfd/'\n",
    "master_data = op.join(proj_dir, 'data/subject_lists/EMOfd_subject_info_211026.csv')\n",
    "\n",
    "df = pd.read_csv(master_data)\n",
    "\n",
    "participant_IDs = pd.unique(df.loc[(df.exclude_from_analysis == False), 'participantID']).tolist()\n",
    "for ID in participant_IDs:\n",
    "    df.loc[df['participantID'] == ID, 'exclude_whole_row'] = False\n",
    "value_counts = df[(df['exclude_whole_row'] == False) & (df['match'] == 1.0)].group.value_counts()\n",
    "endorse_count = value_counts['ENDORSE']\n",
    "oppose_count = value_counts['OPPOSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oppose: 21 + endorse: 21 = 42'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Change this for your study\n",
    "\n",
    "# From the docs: (https://nipype.readthedocs.io/en/v0.14.0/interfaces/generated/interfaces.fsl/model.html)\n",
    "# Contrasts: List of contrasts with each contrast being a list of the form -\n",
    "        # [('name', 'stat', [condition list], [weight list])]\n",
    "# Groups: dictionary containing named lists of regressors\n",
    "  \n",
    "    \n",
    "    \n",
    "## !! IMPORTANT !! \n",
    "\n",
    "# BASED ON DEFAULT GROUP ORDER IN whole_brain.ipynb: \n",
    "\n",
    "# for endorse > oppose, contrast weights should be [1, -1]\n",
    "# for oppose > endorse, contrast weights should be [-1, 1]\n",
    "\n",
    "contrasts = [\n",
    "        ['endorse_gt_oppose', 'T', ['ENDORSE', 'OPPOSE'], [1, -1]]\n",
    "    ]\n",
    "\n",
    "# (otherwise can switch and run ...)\n",
    "\n",
    "#contrasts = [\n",
    "#        ['oppose_gt_endorse', 'T', ['ENDORSE', 'OPPOSE'], [-1, 1]]\n",
    "#    ]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "groups = dict(\n",
    "        ENDORSE = [1] * endorse_count + [0] * oppose_count,\n",
    "        OPPOSE = [0] * endorse_count + [1] * oppose_count,   \n",
    "    )\n",
    "\n",
    "\n",
    "flame_dir = proj_dir+ '/TIER/analysis_data/group_flame'\n",
    "\n",
    "tasks = ['read']\n",
    "\n",
    "outdir = 'group_analysis_output_oppose_gt_endorse_randomise'\n",
    "\n",
    "###\n",
    "\"oppose: {} + endorse: {} = {}\".format(oppose_count, endorse_count, oppose_count + endorse_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_secondlevel_workflow(data_dir, flame_dir, task, outdir, mask, name=\"task-{}_workingdir\"):\n",
    "\n",
    "    con, between_or_all = data_dir.split(task)[1][1:].rsplit('_', 1)\n",
    "    print(between_or_all)\n",
    "    \n",
    "    # Initialize workflow\n",
    "    wf = pe.Workflow(name=name.format(task),\n",
    "                    base_dir=flame_dir)\n",
    "    \n",
    "    # group, con, mat\n",
    "    l2model = pe.Node(interface=MultipleRegressDesign(),\n",
    "                      name='l2model')\n",
    "    \n",
    "    l2model.inputs.contrasts = contrasts\n",
    "    l2model.inputs.regressors = groups\n",
    "    \n",
    "    # copes and varcopes\n",
    "        \n",
    "    templates2 = {'all_copes': 'all_copes*',\n",
    "                     'all_varcopes': 'all_varcopes*'}\n",
    "    get_runs = Node(SelectFiles(templates2),\n",
    "                name='selectruns')\n",
    "    get_runs.inputs.base_directory = op.join(flame_dir, data_dir)\n",
    "    \n",
    "    # maskfile\n",
    "    templates = {'maskfile': mask}\n",
    "    get_mask = Node(SelectFiles(templates),\n",
    "                  name='selectmask')\n",
    "    get_mask.inputs.base_directory = ''\n",
    "    \n",
    "    datasink = pe.Node(nio.DataSink(), name='sinker')\n",
    "    datasink.inputs.base_directory=op.join(flame_dir, outdir)\n",
    "    new_dir = \"randomise_{}_{}\".format(task, con)\n",
    "    datasink.inputs.regexp_substitutions = [\n",
    "        (\"stats_dir\", \"\"), \n",
    "        (\"stats\", new_dir),\n",
    "        ('cov_split_file', new_dir),\n",
    "        ('mask_file', new_dir),\n",
    "        ('var_cope_file', new_dir),\n",
    "        ('cope_file', new_dir),\n",
    "        ('design_file', new_dir),\n",
    "        ('t_con_file', new_dir)\n",
    "    ]\n",
    "\n",
    "    wf.connect([ \n",
    "        (get_runs,datasink,[('all_copes','cope_file'), \n",
    "                                  ('all_varcopes', 'var_cope_file')]),\n",
    "        (l2model,datasink, [('design_mat','design_file'),\n",
    "                                ('design_con','t_con_file'),\n",
    "                                ('design_grp','cov_split_file')]),\n",
    "        (get_mask,datasink,[('maskfile','mask_file')])\n",
    "               ])\n",
    "    \n",
    "    return wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = '/cm/shared/openmind/fsl/5.0.9/data/standard/avg152T1_brain.nii.gz'\n",
    "\n",
    "for task in tasks:\n",
    "    for data_dir in glob.glob('{}/{}*allsubs*'.format(flame_dir, task)):\n",
    "        wf = create_secondlevel_workflow(data_dir, flame_dir, task, outdir, mask)\n",
    "        wf.config['execution'] = {'crashfile_format': 'txt',\n",
    "                                    'remove_unnecessary_outputs': False,\n",
    "                                    'keep_inputs': True}\n",
    "\n",
    "        results = wf.run(plugin='MultiProc')\n",
    "        print(\"Task '{}' is finished\".format(task))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
