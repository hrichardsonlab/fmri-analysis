{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import os.path as op\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "import nilearn\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-09 16:02:37.921502\n",
      "Dec09_2021\n"
     ]
    }
   ],
   "source": [
    "datestring = datetime.now()\n",
    "print(datestring)\n",
    "timestampStr = datestring.strftime(\"%b%d_%Y\")\n",
    "print(timestampStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_190611_out.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_lAmyg.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_lInsIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_lPar.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_rAmyg.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_rClaus.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/disgust_cluster_rInsIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_190805_out.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_lAmyg.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_lIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_lThal.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_lmOccGyr.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_rAmyg.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_rIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/fear_cluster_rITG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_190716_out.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lCingG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lMFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lMTG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lSFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_lTG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_rInsIFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_rMFG.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_rPar.nii.gz', '/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/ROI_MASKS/emo_reg_cluster_rSFG.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "# Get [fear, disgust] maskfiles\n",
    "proj_dir = '/nese/mit/group/saxelab/projects/EMOfd/'\n",
    "path_to_masks = op.join(proj_dir, 'TIER/analysis_data/ROI_MASKS/')\n",
    "maskfiles = []\n",
    "# I am adding this next line for brevity in testing mode \n",
    "#maskfiles += glob.glob(path_to_masks + 'disgust*IFG.nii.gz')\n",
    "\n",
    "# THE NEXT THREE LINES ARE REAL \n",
    "maskfiles += glob.glob(path_to_masks + 'disgust*')\n",
    "maskfiles += glob.glob(path_to_masks + 'fear*')\n",
    "maskfiles += glob.glob(path_to_masks + 'emo_reg*')\n",
    "print(maskfiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up variables for main extraction\n",
    "tier_dir = op.join(proj_dir, 'TIER')\n",
    "copes_dir = op.join(tier_dir,'original_data','copes')\n",
    "varcopes_dir = op.join(tier_dir,'original_data','varcopes')\n",
    "zstats_dir = op.join(tier_dir,'original_data','zstats')\n",
    "first_level_dir = op.join(proj_dir, 'Analysis', 'first_level_standard')\n",
    "path_to_goodvoxel_masks = op.join(proj_dir, 'TIER/analysis_data/ROI_masks_goodvoxels/')\n",
    "\n",
    "# create some directories for outputs \n",
    "outputs_dir = op.join(tier_dir, 'analysis_data/analyzed_ROI_data/multivariate_ROI')\n",
    "top_voxel_mask_outputdir = op.join(outputs_dir, 'subject_top_voxel_masks_' + timestampStr)\n",
    "os.makedirs(top_voxel_mask_outputdir, exist_ok = True)\n",
    "\n",
    "\n",
    "# set the output file names \n",
    "fname_rowbyrow = op.join(outputs_dir, 'multivariate_correlations_and_distances_' + timestampStr + '_preConvert_byRow.csv')\n",
    "# and for after vectors format conversion: \n",
    "fname_converted = op.join(outputs_dir, 'multivariate_correlations_and_distances_' + timestampStr + '_convertedVectors.csv')\n",
    "# and for CSV averaged across folds\n",
    "fname_foldsAve = op.join(outputs_dir, 'multivariate_correlations_and_distances_' + timestampStr + '_aveAcrossFolds.csv')\n",
    "\n",
    "\n",
    "# set the contrasts \n",
    "cons = ['con_1_tgn-gt-cgn', \n",
    "        'con_2_cgd-gt-cgn',\n",
    "        'con_3_cgf-gt-cgn',\n",
    "        'con_4_cgf-gt-cgd',\n",
    "        'con_5_cgd-gt-cgf',\n",
    "        'con_6_cgn',\n",
    "        'con_7_cgd',\n",
    "        'con_8_cgf',\n",
    "        'con_9_tgn', \n",
    "        'con_10_tgn-gt-cgd', \n",
    "        'con_11_tgn-gt-cgf']\n",
    "\n",
    "#cons = ['con_1_tgn-gt-cgn']\n",
    "\n",
    "\n",
    "# set the list of tasks \n",
    "tasks = ['read']\n",
    "# there's only one for now, so we can skip a loop by setting it here. If you add more tasks, you need to build another layer of for-loops over each task\n",
    "task = tasks[0]\n",
    "\n",
    "\n",
    "ROIs = maskfiles\n",
    "# just get the name of the masks (for plotting later)\n",
    "masklabels = list(map(lambda x: x.split('/')[-1].split('.')[0], maskfiles))\n",
    "\n",
    "# either take the whole ROI or just the top 100 voxels -- we'll do both and loop through each option\n",
    "num_top_voxels_options = [100]\n",
    "#num_top_voxels_options = [100, 'whole', 'balanced']\n",
    "\n",
    "# Maximum number of folds (including the fold without any exclusions)\n",
    "# Should = number of runs + 1\n",
    "num_folds = 5\n",
    "\n",
    "# get the info for subjects and exclusions \n",
    "master_data = '/nese/mit/group/saxelab/projects/EMOfd/data/subject_lists/EMOfd_subject_info_211026.csv'\n",
    "df = pd.read_csv(master_data)\n",
    "\n",
    "# this will be a variable in the output CSV .. \n",
    "sub_proj = 'MIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warnings_Dec09_2021.txt\n"
     ]
    }
   ],
   "source": [
    "df_mag = pd.DataFrame(columns=['acquisitionID', 'participantID', 'source', 'task', 'experiment',\n",
    "                               'roi', 'contrast_for_selection', 'contrast1', 'contrast2', 'fold', 'excluded_run', 'voxels_in_roi_mask', \n",
    "                               'good_voxels_in_roi','pearson_r', 'p_score', 'distance',\n",
    "                               'method','mean_top_voxels_combined_fold','mean_top_voxels_left_out', 'missing_data_flag',\n",
    "                               'vector1_curfold_topextracted_con1', 'vector2_leftout_topextracted_con2'])\n",
    "\n",
    "                                                                                                                                \n",
    "df_pearson = pd.DataFrame(columns=masklabels)\n",
    "df_pscore = pd.DataFrame(columns=masklabels)\n",
    "\n",
    "warningfile = 'warnings_' + timestampStr + '.txt'\n",
    "print(warningfile)\n",
    "#writeissue(warningfile, message)\n",
    "def writeissue(filename, message):\n",
    "    f = open(filename, 'a')\n",
    "    f.write(message + '\\n\\n\\n') \n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesubs = pd.unique(df.loc[(df.exclude_from_analysis == False), 'acquisitionID']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM TOP VOXEL TYPE:  whole\n",
      "SUBJECT:  sub-SAXEEMOfd04\n",
      "WORKING ON ROI:  disgust_190611_out\n",
      "(91, 109, 91)\n",
      "GOOD VOXELS IN ROI PROPORTION:\n",
      "1.0\n",
      "WORKING ON FOLD:  1\n",
      "(91, 109, 91)\n",
      "(91, 109, 91)\n",
      "(91, 109, 91)\n",
      "(91, 109, 91)\n",
      "WORKING ON FOLD:  2\n",
      "(91, 109, 91)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-f60ca579e028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                             \u001b[0;31m# mask w/ TOP VOXEL MASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                             \u001b[0mtop_voxel_masked_leftout_fold_cope_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"img1 * img2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleftout_cope_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_voxel_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                             \u001b[0;31m# get data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                             \u001b[0mtop_voxel_masked_leftout_cope_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_voxel_masked_leftout_fold_cope_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mmath_img\u001b[0;34m(formula, **imgs)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m         \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;31m# Add a reference to numpy in the kwargs of eval so that numpy functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda-latest/lib/python3.8/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36m_safe_get_data\u001b[0;34m(img, ensure_finite)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# typically the line below can double memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# that's why we invoke a forced call to the garbage collector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cons = ['con_6_cgn',\n",
    "        'con_7_cgd',\n",
    "        'con_8_cgf',\n",
    "        'con_9_tgn']\n",
    "    \n",
    "for num_top_voxels in num_top_voxels_options:\n",
    "    print('NUM TOP VOXEL TYPE: ', num_top_voxels)\n",
    "    \n",
    "    for sub in filesubs:\n",
    "        print('SUBJECT: ', sub)\n",
    "        participantID = df.loc[df.acquisitionID == sub,'participantID'].values[0]\n",
    "        experiment = df.loc[df.acquisitionID == sub,'experiment'].values[0]\n",
    "    \n",
    "        for roi in ROIs: \n",
    "            mask_img_fname = roi\n",
    "            roi = op.basename(roi).split('.')[0]\n",
    "            print('WORKING ON ROI: ', roi)\n",
    "\n",
    "            #FIND THE SUBJECT'S GOOD-VOXEL ROI MASK (pre-written based on varcope of all contrasts in exclude-none fold)\n",
    "            goodvox_ROI_fname = '{}/ROI_GOODVOX_{}_task-{}_{}.nii.gz'.format(path_to_goodvoxel_masks, sub, task, roi)\n",
    "            matches_goodvox_ROI = glob.glob(goodvox_ROI_fname)\n",
    "            mask_img = image.load_img(matches_goodvox_ROI[0])\n",
    "\n",
    "            # load the ROI image\n",
    "            mask_img_data = mask_img.get_fdata()\n",
    "            print(mask_img_data.shape)\n",
    "\n",
    "            # find N voxels in the good-voxel-only ROI \n",
    "            voxel_filter = np.abs(mask_img_data) > 0.0\n",
    "            good_voxels_in_roi = np.sum(voxel_filter)\n",
    "            np.set_printoptions(threshold=good_voxels_in_roi+100)\n",
    "\n",
    "\n",
    "            # load the original ROI image to determine missing_data_flag \n",
    "            mask_img_ORIG = image.load_img(mask_img_fname)\n",
    "            mask_img_ORIG_data = mask_img_ORIG.get_fdata()\n",
    "            voxels_in_orig_roi = np.sum(np.abs(mask_img_ORIG_data) > 0.0)\n",
    "            \n",
    "            print(\"GOOD VOXELS IN ROI PROPORTION:\")\n",
    "            print(good_voxels_in_roi/voxels_in_orig_roi)\n",
    "            if good_voxels_in_roi/voxels_in_orig_roi < .80:\n",
    "                missing_data_flag = True\n",
    "                message = 'missing data flag set true for: {}, {}'.format(sub, roi)\n",
    "                writeissue(warningfile, message)\n",
    "            else:\n",
    "                missing_data_flag = False\n",
    "\n",
    "\n",
    "            for fold in range(1, num_folds):\n",
    "                print('WORKING ON FOLD: ', fold)\n",
    "\n",
    "                for con in cons: \n",
    "\n",
    "                        \n",
    "                    contrast_for_selection = 'con_4_cgf-gt-cgd'\n",
    "                    combZ_current_fold = '{}/{}_{}_fold_{}_exclude_{}_{}_zstat.nii.gz'.format(zstats_dir, sub, task, fold, 'run*', contrast_for_selection)\n",
    "                    matches_combZ_current_fold = glob.glob(combZ_current_fold)\n",
    "\n",
    "                    if len(matches_combZ_current_fold) > 1:\n",
    "                        print('There are duplicate fear files present.')\n",
    "                        message = 'There are duplicate files present for: ' + combZ_current_fold\n",
    "                        writeissue(warningfile, message)\n",
    "                        pass\n",
    "                    elif len(matches_combZ_current_fold) < 1:\n",
    "                        print(combZ_current_fold, ' is missing!')\n",
    "                        message = 'The file is missing: ' + combZ_current_fold\n",
    "                        writeissue(warningfile, message)\n",
    "                        pass\n",
    "                    else:\n",
    "                        combZ_img = image.load_img(matches_combZ_current_fold[0])\n",
    "                        print(combZ_img.shape)\n",
    "\n",
    "\n",
    "                        # mask our train contrast using the good-voxel ROI mask -- i.e. turn every voxel in cope not in ROI to 0\n",
    "                        masked_combZ_img = image.math_img(\"img1 * img2\", img1 = combZ_img, img2 = mask_img)\n",
    "\n",
    "                        # actually get the data (real values) from the masked copes \n",
    "                        masked_combZ_data = masked_combZ_img.get_fdata()\n",
    "\n",
    "\n",
    "                        #NEXT: DROP THE ZEROS\n",
    "                        # create copies \n",
    "                        nanned_combZ_data = masked_combZ_data.copy()\n",
    "                        nanned_combZ_data[nanned_combZ_data == 0] = np.nan\n",
    "                        combZ_roi_nans_inds = (-nanned_combZ_data).argsort(axis = None)\n",
    "\n",
    "                        \n",
    "\n",
    "                        ## GET WHICH VOXELS ARE TOP \n",
    "                        if num_top_voxels == 'whole':\n",
    "                            nVox = np.count_nonzero(voxel_filter) #however many voxels there are in the good-voxel ROI\n",
    "                            # still create a mask based on the masked z-data, but just take the WHOLE thing... unncessary, but whatever!\n",
    "                            masked_combZ_data[np.unravel_index(combZ_roi_nans_inds[nVox:], masked_combZ_data.shape)] = np.nan\n",
    "                            top_voxel_fname = '{}/{}_task-{}_fold-{}_{}_whole_good-ROI.nii.gz'.format(top_voxel_mask_outputdir, sub, task, fold, roi)\n",
    "                        \n",
    "                        elif num_top_voxels == 'balanced':\n",
    "                            to_play = masked_combZ_data[np.unravel_index(combZ_roi_nans_inds, masked_combZ_data.shape)]\n",
    "                            zero_ind = (np.where(to_play==0)[0][0])\n",
    "                            if (np.count_nonzero(voxel_filter)) < 100:\n",
    "                                nVox = int(np.floor(np.count_nonzero(voxel_filter)/2.0))\n",
    "                            else:\n",
    "                                nVox = 50\n",
    "                            masked_combZ_data[np.unravel_index(combZ_roi_nans_inds[nVox:(zero_ind-nVox)], masked_combZ_data.shape)] = np.nan\n",
    "                            masked_combZ_data[np.unravel_index(combZ_roi_nans_inds[zero_ind:], masked_combZ_data.shape)] = np.nan                        \n",
    "                            top_voxel_fname = '{}/{}_task-{}_fold-{}_{}_balanced_top_contrast-{}_from-zstat.nii.gz'.format(top_voxel_mask_outputdir, sub, task, fold, roi, contrast_for_selection)\n",
    "                        \n",
    "                        elif num_top_voxels == 100:\n",
    "                            combZ_roi_nans_inds = (-np.absolute(nanned_combZ_data)).argsort(axis = None)\n",
    "                            nVox = min(num_top_voxels, np.count_nonzero(voxel_filter))\n",
    "                            masked_combZ_data[np.unravel_index(combZ_roi_nans_inds[nVox:], masked_combZ_data.shape)] = np.nan\n",
    "                            top_voxel_fname = '{}/{}_task-{}_fold-{}_{}_top-100_contrast-{}_from-zstat.nii.gz'.format(top_voxel_mask_outputdir, sub, task, fold, roi, contrast_for_selection)\n",
    "\n",
    "                            \n",
    "                        # GET BINARY MASKS (1,0) OF WHICH VOXELS ARE TOP IN OUR TRAIN DATA \n",
    "                        top_voxel_mask = masked_combZ_data.copy()\n",
    "                        top_voxel_mask[~np.isnan(top_voxel_mask)] = 1\n",
    "                        top_voxel_mask[np.isnan(top_voxel_mask)] = 0\n",
    "\n",
    "\n",
    "                        # save the top voxel masks to files \n",
    "                        top_voxel_img = image.new_img_like(combZ_img, top_voxel_mask)\n",
    "                        top_voxel_img.to_filename(top_voxel_fname)\n",
    "                        \n",
    "\n",
    "                        ### NOW MOVING ON TO PULLING BETAS FROM TOP VOXELS \n",
    "                        \n",
    "                        # get the excluded run \n",
    "                        splits_1 = test.split('exclude_')\n",
    "                        splits_2 = splits_1[1].split('_')\n",
    "                        excluded_run = splits_2[0]\n",
    "                            \n",
    "                        # get cope (betas) from top voxels in 3/4 fold\n",
    "\n",
    "                        #print('WORKING ON CURRENT-FOLD CONDITION: ', con)\n",
    "                        current_fold_cope_fname = '{}/{}_{}_fold_{}_exclude_{}_{}_cope.nii.gz'.format(copes_dir, sub, task, fold, 'run*', con)\n",
    "                        matches_current_fold_cope_fname = glob.glob(current_fold_cope_fname)\n",
    "\n",
    "                        if len(matches_current_fold_cope_fname) != 1:\n",
    "                            print('Incorrect # of files present for:')\n",
    "                            print(current_fold_cope_fname)\n",
    "                            message = 'Incorrect # of files present for current-fold condition-cope: {},{},{},{}'.format(sub, fold, con, roi)\n",
    "                            writeissue(warningfile, message)\n",
    "\n",
    "                        # load the image \n",
    "                        current_fold_cope_img = image.load_img(matches_current_fold_cope_fname[0])\n",
    "\n",
    "                        # mask w/ TOP VOXEL MASK \n",
    "                        top_voxel_masked_current_fold_cope_img = image.math_img(\"img1 * img2\", img1 = current_fold_cope_img, img2 = top_voxel_img)\n",
    "\n",
    "                        # get data \n",
    "                        top_voxel_masked_current_fold_cope_data = top_voxel_masked_current_fold_cope_img.get_fdata()\n",
    "\n",
    "                        # ravel \n",
    "                        top_voxel_masked_current_fold_cope_data[top_voxel_masked_current_fold_cope_data==0] = np.nan \n",
    "                        tempravel_top_voxel_masked_current_fold_cope_data = np.ravel(top_voxel_masked_current_fold_cope_data)\n",
    "                        raveled_top_current_fold = tempravel_top_voxel_masked_current_fold_cope_data[~np.isnan(tempravel_top_voxel_masked_current_fold_cope_data)]\n",
    "\n",
    "                        ## start loop for test2 -- i.e. the leftout cond \n",
    "\n",
    "                        for con2 in cons:\n",
    "                            #print('WORKING ON LEFT-OUT CONDITION: ', con2)\n",
    "                            leftout_cope_fname = '{}/{}/{}/model/{}/{}_cope.nii.gz'.format(first_level_dir, sub, task, excluded_run, con2)\n",
    "                            matches_leftout_cope_fname = glob.glob(leftout_cope_fname)\n",
    "\n",
    "                            if len(matches_leftout_cope_fname) != 1:\n",
    "                                print('Incorrect # of files present for:')\n",
    "                                print(leftout_cope_fname)\n",
    "                                message = 'Incorrect # of files present for left-out condition-cope: {},{},{},{}'.format(sub, excluded_run, con2, roi)\n",
    "                                writeissue(warningfile, message)\n",
    "\n",
    "                            # load the image \n",
    "                            leftout_cope_img = image.load_img(matches_leftout_cope_fname[0])\n",
    "\n",
    "                            # mask w/ TOP VOXEL MASK\n",
    "                            top_voxel_masked_leftout_fold_cope_img = image.math_img(\"img1 * img2\", img1 = leftout_cope_img, img2 = top_voxel_img)\n",
    "                            # get data \n",
    "                            top_voxel_masked_leftout_cope_data = top_voxel_masked_leftout_fold_cope_img.get_fdata()\n",
    "\n",
    "                            # ravel \n",
    "                            top_voxel_masked_leftout_cope_data[top_voxel_masked_leftout_cope_data==0] = np.nan\n",
    "                            tempravel_top_voxel_masked_leftout_cope_data = np.ravel(top_voxel_masked_leftout_cope_data)\n",
    "                            raveled_top_leftout = tempravel_top_voxel_masked_leftout_cope_data[~np.isnan(tempravel_top_voxel_masked_leftout_cope_data)]\n",
    "\n",
    "                            # can save raveled_top_leftout here \n",
    "\n",
    "\n",
    "                            ## GET CORRELATION \n",
    "                            if len(raveled_top_current_fold) < 2 or (len(raveled_top_current_fold) != len(raveled_top_leftout)):\n",
    "                                print(\"ROI = {}, -- CUR-FOLD len: {}, LEFT-OUT len: {}\".format(roi, len(raveled_top_current_fold), len(raveled_top_leftout)))\n",
    "                                message = 'mismatch between top-voxel-mask of current-fold condition cope and leftout condition cope: {},fold {}, excluded {}, con1 {}, con2 {}, {}; cur-fold-length= {}, left-out-length= {}'.format(sub, fold, excluded_run, con, con2, roi, len(raveled_top_current_fold), len(raveled_top_leftout))\n",
    "                                writeissue(warningfile, message)\n",
    "                                continue\n",
    "                            pearson_r = scipy.stats.pearsonr(raveled_top_current_fold, raveled_top_leftout)\n",
    "                            #print(pearson_r)\n",
    "\n",
    "                            mean_top_vox_curfold = np.nanmean(top_voxel_masked_current_fold_cope_data)\n",
    "                            mean_top_vox_leftout = np.nanmean(top_voxel_masked_leftout_cope_data)\n",
    "\n",
    "\n",
    "                            # get distance \n",
    "                            dist = distance.euclidean(raveled_top_current_fold, raveled_top_leftout)\n",
    "                            \n",
    "                        \n",
    "                            \n",
    "                            if num_top_voxels == 'whole':\n",
    "                                sel_cond = 'NaN'\n",
    "                            elif num_top_voxels == 'balanced': \n",
    "                                sel_cond = 'con_4_cgf-gt-cgd'\n",
    "                            elif num_top_voxels == 100:\n",
    "                                sel_cond = 'con_4_cgf-gt-cgd'\n",
    "\n",
    "                            df_mag_currentrow = pd.DataFrame({'acquisitionID' : sub, 'participantID': participantID, \n",
    "                                                                    'source': sub_proj,\n",
    "                                                                    'task' : task, 'experiment': experiment, 'roi' : roi,\n",
    "                                                                    'contrast_for_selection': sel_cond,\n",
    "                                                                    'contrast1' : con, \n",
    "                                                                    'contrast2': con2,\n",
    "                                                                    'fold': fold,\n",
    "                                                                    'excluded_run': excluded_run,\n",
    "                                                                    'voxels_in_roi_mask': voxels_in_orig_roi, \n",
    "                                                                    'good_voxels_in_roi': good_voxels_in_roi,\n",
    "                                                                    'pearson_r' : pearson_r[0],\n",
    "                                                                    'p_score': pearson_r[1],\n",
    "                                                                    'distance' : dist,\n",
    "                                                                    'method' : num_top_voxels,\n",
    "                                                                    'mean_top_voxels_combined_fold' : mean_top_vox_curfold,\n",
    "                                                                    'mean_top_voxels_left_out' : mean_top_vox_leftout,\n",
    "                                                                    'missing_data_flag' : missing_data_flag,\n",
    "                                                                    'vector1_curfold_topextracted_con1': [raveled_top_current_fold], \n",
    "                                                                    'vector2_leftout_topextracted_con2': [raveled_top_leftout]})\n",
    "\n",
    "\n",
    "                            if not os.path.isfile(fname_rowbyrow):\n",
    "                           #     # if file doesn't exist, write it with column headers \n",
    "                                df_mag_currentrow.to_csv(fname_rowbyrow, index=False, header='column_names')\n",
    "                            else: \n",
    "                           #     # else append w/o column headers \n",
    "                                df_mag_currentrow.to_csv(fname_rowbyrow, mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "           #                 df_mag = df_mag.append({'acquisitionID' : sub, 'participantID': participantID, \n",
    "           #                                                         'source': sub_proj,\n",
    "           #                                                         'task' : task, 'experiment': experiment, 'roi' : roi,\n",
    "           #                                                         'contrast1' : con, \n",
    "           #                                                         'contrast2': con2,\n",
    "           #                                                         'fold': fold,\n",
    "           #                                                         'excluded_run': excluded_run,\n",
    "           #                                                         'voxels_in_roi_mask': voxels_in_roi, \n",
    "           #                                                         'good_voxels_in_roi': good_voxels_in_roi,\n",
    "           #                                                         'pearson_r' : pearson_r[0],\n",
    "           #                                                         'p_score': pearson_r[1],\n",
    "           #                                                         'distance' : dist,\n",
    "           #                                                         'method' : num_top_voxels,\n",
    "           #                                                         'mean_top_voxels_combined_fold' : mean_top_vox_curfold,\n",
    "           #                                                         'mean_top_voxels_left_out' : mean_top_vox_leftout,\n",
    "           #                                                         'missing_data_flag' : missing_data_flag,\n",
    "           #                                                         'vector1_curfold_topextracted_con1': raveled_top_current_fold, \n",
    "           #                                                         'vector2_leftout_topextracted_con2': raveled_top_leftout}, ignore_index = True)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(string):\n",
    "    ls = string[1:-1].split()\n",
    "    return list(map(float, ls)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nese/mit/group/saxelab/projects/EMOfd/TIER/analysis_data/analyzed_ROI_data/multivariate_ROI/multivariate_correlations_and_distances_Dec09_2021_preConvert_byRow.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfmag_whole = pd.read_csv(fname_rowbyrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmag_whole['vector1_curfold_topextracted_con1'] = dfmag_whole['vector1_curfold_topextracted_con1'].apply(convert)\n",
    "dfmag_whole['vector2_leftout_topextracted_con2'] = dfmag_whole['vector2_leftout_topextracted_con2'].apply(convert)\n",
    "\n",
    "dfmag_whole.to_csv(fname_converted, index=False, header=\"column_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmag_whole = pd.read_csv(fname_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = dfmag_whole.groupby(['participantID', 'roi', \n",
    "                     'contrast1', 'contrast2','method']).agg({'mean_top_voxels_combined_fold': ['mean'],\n",
    "                                                              'mean_top_voxels_left_out': ['mean'], \n",
    "                                                              'pearson_r': ['mean'], \n",
    "                                                              'p_score': ['mean'], \n",
    "                                                              'distance': ['mean']})\n",
    "\n",
    "df_new.columns = ['mean_top_voxels_combined_fold_aveAcrossFolds', \n",
    "                  'mean_top_voxels_left_out_aveAcrossFolds', \n",
    "                  'pearson_r_aveAcrossFolds', 'p_score_aveAcrossFolds', \n",
    "                  'distance_aveAcrossFolds']\n",
    "\n",
    "df_re = df_new.reset_index()\n",
    "#df_re = df_re.drop(columns=[\"method\"])\n",
    "df_re = df_re.sort_values(by=['participantID', 'roi', 'contrast1', 'contrast2'])\n",
    "\n",
    "df_re.to_csv(fname_foldsAve, index=False, header='column_names')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
